---
layout: post
title: "Accompaniment Generation for Melodies"
author: "Chandra Gummaluru"
categories: projects
---

This project concerns the creation of a machine learning model capable of adding accompaniments to melodies. The hope is that a user can upload a recording of themselves playing a melody, and then download the recording with a generated accompaniment added on.

## Acousitics and Music Theory
### Sounds and Waves
A sound is simply a vibration that propogates as an audible wave of pressure through a medium. We can represent sound mathematically as a wave. The simplest wave is arguably a sinusoidal wave, such as $A\cos(wt)$ where $A$ is the amplitude, $\omega$ is the angular frequency, and $t$ is time.

For example, we plot a 2 Hz sinusoidal wave, with an amplitude of 0.5, below:

It turns out that the average human can hear frequencies between 20 Hz to 22 kHz, and so the above wave would actually be inaudible. However, if we change the frequency to be within that range, say 440 Hz, it sounds something like this:

<audio controls src="https://github.com/chandra-gummaluru/chandra-gummaluru.github.io/raw/46cfd9d7f4f59a3df411da0092624402276d2c33/assets/440hz_wave.wav"></audio>

Since $\cos{t}$ is $2\pi$ periodic, the **temporal frequency**, $f$ of the wave is given by
$$f = \frac{\omega}{2\pi}.$$

The **percieved pitch** of a sound wave is directly proportional to this frequency. However, the **percieved pitch _difference_** between two sound waves is logarithmic w.r.t. the frequencies. For example, the pitch difference between a 220 Hz and 440 Hz wave is the same as that between the 440 Hz and an 880 Hz wave.
