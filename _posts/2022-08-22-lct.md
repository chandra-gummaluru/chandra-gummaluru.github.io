---
layout: post
title: "Course Notes: Linear Control Theory"
author: "Chandra Gummaluru"
---

The following notes are heavily based on material developed by Professor Margret Chapman for [ECE557 taught at the University of Toronto]()
  
# Signals
> **Def. Signal:** An $n$-dimensional continuous-time signal, $s: \mathbb{R} \rightarrow \mathbb{R}^n$, is a function of time. We write $s(t)$ to denote the signal's value at time, $t$.

A few important operations on signals include:
- **value-scaling**: $s'(t) := \alpha s(t)$, where $\alpha \in \mathbb{R}$
- **value-shifting**: $s'(t) := s(t) + \beta$, where $\beta \in \mathbb{R}$
- 

# Dynamical Systems
A **dynamical system** is anything that can be modelled as an operator, $\mathcal{S}$ that takes an input signal, $u: \mathbb{R} \rightarrow \mathbb{R}^m$, and gives an output signal, $y: \mathbb{R} \rightarrow \mathbb{R}^p$, i.e., $y = \mathcal{S}(u)$.
<br><br>
Note that $u$ and $y$ are signals, i.e., functions of time.
<br><br>
We say that $\mathcal{S}$ is _linear_ if
\\[\mathcal{S}(u_1 + \alpha\mathcal{S}(u_2) = \mathcal{S}(u_1) + \alpha\mathcal{S}(u_2),\\]
and time-invariant iff
\[\]
