---
layout: post
title: "Course Notes: Linear Control Theory"
author: "Chandra Gummaluru"
---

The following notes are heavily based on material developed by Professor Margret Chapman for [ECE557 taught at the University of Toronto]()
  
# Signals and Linear Time-Invariant Systems

## Signals as Functions of Time
> **Def. Continuous-Time Signal:** A **continuous-time signal** is a function, $u: \mathbb{R} \rightarrow \mathbb{R}$ where $u(t)$ is the signal's value at time, $t$.
 
We will often view a continuous-time signal, $x$, as linear combinations of basis signals, say
\\[u(t) = \sum\_{k}\hat{u}\_k\phi_k(t).\\]
Some continuous-time signals exhibit special properties which can often be exploited to simplify their analysis. We now define some of these properties.
<br><br>
We begin with the notion of even/odd-ness.
> **Def. Even/Odd Continuous-Time Signal:** A continuous-time signal, $u$, is **even** iff $u(t) = u(-t), \forall t \in \mathbb{R}$ and **odd** if $u(t) = -u(-t)$ for
> all $t \in \mathbb{R}$.

It turns out that any continuous-time signal, $u$, can be decomposed into a linear combination of even/odd components.

> **Thm. Even/Odd Decomposition of Continuous-Time Signals:** Any continuous-time signal, $u$, can be decomposed into odd and even components, namely,
> \\[u(t) = u^{\text{e}}(t) + u^{\text{o}}(t),\\]
> where
> \\[u^{\text{e}}(t) = \frac{1}{2}\left[u(t) + u(-t)\right] \text{ and } u^{\text{o}}(t) = \frac{1}{2}\left[u(t) - u(-t)\right].\\]

We consider a few important transformations of continuous-time signals.
> **Def. Continuous-Time Time Shifting:** A signal, $u\_{\tau}: \mathbb{R} \rightarrow \mathbb{R}$ is a **time-shift** of a signal, $u: \mathbb{R} \rightarrow \mathbb{R}$, if
> \\[u_{\tau}(t) = u(t-\tau), \forall t.\\]
> For $\tau > 0$, the time-shift is into the past, and for $\tau < 0$, it is into the future.

## Signals as Distributions

In theory, it is possible to measure a continuous-time signal exactly at any time, $t \in \mathbb{R}$. However, in practice we must often resort to computing a (possibly non-uniform) mean measurement of the signal within some bounded region, $R_t$ around $t$. More precisely, we may only compute
\\[\int_{R_t}\phi(\tau)u(\tau)d\tau,\\]
where $\phi: \mathbb{R} \rightarrow \mathbb{C}^{p,p}$ denotes the weighting over $R_t$.

Thus, rather than representing continuous-time signals as functions, we will use a new construct called a distribution.
> **Def. Distribution:** A **distribution**, $T: \mathcal{D} \rightarrow \mathbb{C}$ is a linear functional where $\mathcal{D}$ is a set of test functions on which $T$ acts. The notation $\langle T, \phi \rangle$ is used to denote the distribution, $T$, acting on the test function $\phi \in \mathcal{D}$.

> **Def. Equivalent Distributions:** Two distributions, $T_1$ and $T_2$ are equivalent, denoted $T_1 = T_2$ iff
> \\[\langle T_1, \phi \rangle = \langle T_2, \phi \rangle,\\]
> for any appropriate test function, $\phi$.

Many conventional functions can be represented as distributions.

> **Def. Distribution of a Function**: Any (locally integrable) function, $x$, may be represented as a distribution via the mapping
> \\[\langle T_x, \phi \rangle \mapsto \int_{\text{dom}{x}}x(t)\phi(t)dt,\\]
> where $T_x$ denotes the distributional analogue or **regular distribution** of $x$.
> In a common abuse of notation, $x$ is also used to denote its regular distribution, $T_x$.

We now consider transformations of distributions, which follow from requiring that they be consistent with the conventional ones for regular distributions.

- **Sum of Two Distributions:** Let $T_1$ and $T_2$ be two distributions. Then, we define $T_1 + T_2$ as the distribution such that \\[\langle T_1 + T_2, \phi \rangle = \langle T_1, \phi \rangle + \langle T_2, \phi \rangle.\\]

- **Time-Shift of a Distribution**: For any distribution, $T$, and $d \in \mathbb{R}$, we define the backward time-shift, $T_d$, as a distribution such that \\[\langle T_d, \phi \rangle = \langle T, \phi_{-d} \rangle.\\]

- **Product with a Smooth Function**: For any distribution, $T$, and smooth function, $s$, we define the distributional product $T \cdot s$ so that \\[\langle T \cdot s, \phi \rangle = \langle T, s \cdot \phi \rangle.\\]

# Linear Time-Invariant Systems
A system is anything that takes in an input and produces an output.

> **Def. Continuous-Time System:** A **continuous-time system** is an operator, $\mathcal{T}$, that maps one continuous-time signal, $u: \mathbb{R}\_{+} \rightarrow \mathbb{R}^m$ to another continuous-time signal, $y = \mathcal{T}[u]$, where $y: \mathbb{R}\_{+} \in \mathbb{R}^p$.

We assume that the output of the system at time $t$, i.e., $y(t)$, given some input signal $u$, depends only on the value(s) of $u$ at or before $t$, i.e., $u(0),\dots,u(t)$. Such a system is said to be **causal**.

For a causal system, we can express $y(t)$ using a recursive definition:
\\[\begin{aligned}
\dot{x}(t) &= f(x(t), u(t),t) \\\\\\
y(t) &= g(x(t), u(t),t),
\end{aligned}\tag{DynSys}\\]
where $x:\mathbb{R}\_{+} \rightarrow \mathbb{R}^n, f: \mathbb{R}^{n} \times \mathbb{R}^{m}$ and $g: \mathbb{R}^{n} \times \mathbb{R}^{m} \rightarrow \mathbb{R}^{p}$. We refer to $x(t)$ as the state of the system at time, $t$.
<br><br>
We will consider systems in which $f$ and $g$ are constant w.r.t. $t$, or equivalently, systems in which
\\[y(t) = \mathcal{T}\left\[u(\tau) \right\](t) \Rightarrow y(t - t_0) = \mathcal{T}\left\[ u(\tau-t_0) \right\](t), \forall t_0.\\]
Such systems are called **time-invariant**.
<br><br>
If we knew $x(t), \forall t$, it would be relatively easy to compute $y(t), \forall t$. However, we often only know the initial state, $x_0 = x(0)$. To determine $x(t)$, we need to solve the initial-value problem
\\[
\begin{aligned}
\dot{x} &= f(x,u) \\\\\\
x(0) &= x_0.
\end{aligned}
\\]
This is difficult to do in general. However, we will focus on systems in which $f$ and $g$ are _linear_ functions, i.e.,
\\[\begin{aligned}
\dot{x}(t) &= Ax(t) + Bu(t) \\\\\\
y(t) &= Cx(t) + Du(t),
\end{aligned}\tag{LinDynSys}\\]
where $A \in \mathbb{R}^{n,n}, B \in \mathbb{R}^{n,m}, C \in \mathbb{R}^{p,n}, D \in \mathbb{R}^{p,m}$, or equivalently, systems in which for any input signals, $u\_1$ and $u\_2$, and scalars $a_1$ and $a_2$, we have
\\[\mathcal{T}\left[ a_1u_1(t) + a_2u_2(t) \right] = a_1\mathcal{T}\left[ u_1(t) \right] + a_2\mathcal{T}\left[ u_2(t) \right].\\]

The system described by (LinDynSys) is called a linear time-invariant (LTI) system. In many cases, we actually do not need to solve (LinDynSys) because $y(t)$ can be entirely determined by the system's response to a unit impulse, i.e., its impulse response.

> **Thm. Response of a Continuous-Time Linear System:** Consider a continuous-time LTI system with an impulse response, $h(t) = \mathcal{T} \lbrace \delta(t) \rbrace$. Then for any other continuous-time signal, $u: \mathbb{R} \rightarrow \mathbb{R}^m$,
> \\[\mathcal{T}\lbrace u(\tau) \rbrace(t) = (u * h)(t) := \int_{-\infty}^{\infty}h(t - \tau)u(\tau)d\tau,\\]
> where $h: \mathbb{R} \rightarrow \mathbb{R}^{p \times m}$.

The continuous-time convolution operator, $\*$, satisfies the following properties:
- **Distributivity:** $(h\_1 + h\_2)\*u = h\_1\*u + h\_2\*u$,
- **Commutativity:** $h \* u = h \* x$,
- **Associativity:** $(h\_1 \* h\_2) \* u = h\_1 \* (h\_2 \* u)$.

As a result, continuous-time LTI systems are also distributive, commutative, and associative.


> **Thm. Impulse Response of a Causal LTI System:** The impulse response, $h$, of a causal continuous-time LTI system is always such that \\[h(t) = 0, \forall t < 0.\\]

<details>
 <summary><strong>See proof</strong>.</summary>
<p>
Consider the response $y: \mathbb{R} \rightarrow \mathbb{R}^p$ of the system to an arbitrary continuous-time signal, $u: \mathbb{R} \rightarrow \mathbb{R}^m$. We have
\[y(t) = (x * h)(t) = (h * x)(t)\]
$\begin{aligned}
&= \int_{-\infty}^{\infty}h(\tau)u(t- \tau)d\tau \\
&= \int_{-\infty}^{0}h(\tau)u(t - \tau)d\tau + \int_{0}^{\infty}h(\tau)u(t-\tau)d\tau
\end{aligned}$
<br><br>
To satisfy causality, the first sum must evaluate to zero for any $u$, and so $h(t) = 0, \forall t < 0$. $\blacksquare$
</p>
</details>

It turns out that exponential signals, i.e., those of the form, $e^{st}$, where $s \in \mathbb{C}^m$, are eigensignals of LTI systems.

> **Def. Response of a Continuous-Time LTI System to an Exponential:** The response of a continuous-time LTI system $\mathcal{T}$ to a signal of the form, $e^{st}$ is \\[\mathcal{T}\lbrace e^{st} \rbrace(t) = H(s)e^{st},\\]
where $H(s) = \mathscr{L}\lbrace h(t) \rbrace(s) \in \mathbb{C}^{p \times m}$ is called the **system function**.

<details>
 <summary><strong>See proof</strong>.</summary>
<p>
Let $u(t) = e^{st}$ where $s \in \mathbb{C}^{m}$. We have
\[y(t) = \mathcal{T}\lbrace u(t) \rbrace(t) = (h * u)(t)\]
$\begin{aligned}
&= \int_{-\infty}^{\infty}h(\tau)u(t-\tau)d\tau \\
&= \int_{-\infty}^{\infty}h(\tau)e^{s(t-\tau)}d\tau \\
&= \underbrace{\left(\int_{-\infty}^{\infty}h(\tau)e^{-s\tau}d\tau\right)}_{\mathscr{L}\lbrace h \rbrace(s)}e^{st}. \blacksquare
\end{aligned}$
</p>
</details>

> **Def. System Function:** Consider a continuous-time LTI system, $\mathcal{T}$, with a system function, $H$. Suppose $y$ is the output of $\mathcal{T}$ to a signal, $x$, i.e.,
> \\[y(t) = \mathcal{T}\lbrace u(t)\rbrace(t).\\]
> It follows that $Y(s) = H(s)U(s)$, where $U(s) = \mathscr{L}\lbrace u(t)\rbrace(s)$ and $Y(s) = \mathscr{L}\lbrace y(t)\rbrace(s)$.

Of course, the problem with this approach is that we must know $h$ (or $H$). In many cases, we only know $A,B,C,D$.

## The Solution to $\dot{x} = Ax$
Our goal now is to find a closed form expression for $x$ that satisfies (\ref{}) given some initial state $x(0) = x_0 \in \mathbb{R}^{n}$ and input $u$. For now, we will assume that either $B = \mathbf{0}$ and/or $u \equiv 0$, leading to the following initial-value problem:
\\[\begin{aligned}
\dot{x} &= Ax \\\\\\
x(0) &= x_0.
\end{aligned}\\]
Suppose that we replace the matrix $A$ in (\ref{}) with a scalar $a$, i.e., we consider the initial-value problem
\\[\begin{aligned}
\dot{x} &= ax \\\\\\
x(0) &= x_0.
\end{aligned}\\]
We can easily verify that $x(t) = x_0e^{at}$ is a solution. Indeed we have $\dot{x}(t) = ax_0e^{at} = ax(t)$ and $x(0) = x_0$.
<br><br>
We might expect a similar result to hold for (\ref{}), provided we define the exponential of a matrix such that it generalizes the scalar definition. 
<br><br>
To define the exponential of a matrix, $A$, we turn to the series representation for the exponential of a scalar, $a$:
\\[e^{a} := \sum_{k=0}^{\infty}\frac{a^k}{k!}.\\]
The advantage of the series representation is that it can readily extend to the matrix case simply by replacing $a$ with $A$.
> **Def. Matrix Exponential:** The exponential of a matrix $A$ is given by the infinite series,
> \\[e^{A} := \sum_{k=0}^{\infty}\frac{A^k}{k!},\\]
> where by definition, $A^{0} = I$.

Computing $e^{A}$ using the definition is tedious, and so, we now develop some alternative approaches. We begin by considering the trivial but instructive special case where $A$ is diagonal, i.e., $A = \mathrm{diag}(a_1, \dots, a_n)$. We compute
\\[e^{A} = e^{\textrm{diag}(a_1, \dots, a_n)} = \sum_{0 = 1}^{\infty}\frac{\textrm{diag}(a_1, \dots, a_n)^k}{k!} = \textrm{diag}\left(\sum_{k=0}^{\infty}\frac{a_1^k}{k!}, \dots, \sum_{k=0}^{\infty}\frac{a_n^k}{k!}\right) = \textrm{diag}(e^{a_1}, \dots, e^{a_n}).\\]
We see that the matrix exponential of a diagonal matrix is the scalar exponential of each of its elements. We can use this result to derive a relatively simple formula for $e^{A}$ even if $A$ is not necessarily diagonal, so long as it is diagonalizable.
> **Thm. Computing $e^{A}$ when $A$ is Diagonalizable:** Suppose $A \in \mathbb{R}^{n,n}$ is diagonalizable, i.e., there exists a square matrix, $P \in \mathbb{R}^{n,n}$, and diagonal matrix, $\Delta = \textrm{diag}(\lambda_1, \dots, \lambda_n) \in \mathbb{R}^{n,n}$ such that $A = P\Delta P^{-1}$. Then, we have
> \\[e^{A} = Pe^{\Delta}P^{-1} \text{ where } e^{\Delta} = \begin{bmatrix}
e^{\lambda_1} & & \\\\\\
& \ddots & \\\\\\
& & e^{\lambda_n}
\end{bmatrix}.\\]

<details>
 <summary><strong>See proof</strong>.</summary>
<p>
Assume $A = P\Delta P^{-1}$. We have
\[e^{A} = e^{P\Delta P^{-1}} = \sum_{k=0}^{\infty}\frac{(P\Delta P^{-1})^{k}}{k!} = P\sum_{k=0}^{\infty}\frac{\Delta^k}{k!}P^{-1} = Pe^{\Delta P^{-1}.}\]
</p>
</details>

To use the aforementioned theorem, we need the eigenvalues and eigenvectors of $A$, which can be complex-valued even if the elements of $A$ are real. While the formulation is still valid in such cases, the representation can be somewhat non-intuitive, particularly since the definition of $e^{A}$ clearly implies that $e^{A} \in \mathbb{R}^{n,n}$ if $A \in \mathbb{R}^{n,n}$. Ideally, we would avoid intermediate computations that involve complex values.
<br><br>
Thus, we now consider an alternative approach. We recall that the eigen-values/vectors of a matrix come in complex conjugate pairs, i.e., if $(\lambda, v)$ is an eigen-value/vector pair, then so too is $(\lambda^*, v^*)$.
<br><br>
Generally, we have $P = \begin{bmatrix}
\dots & v & v^* & \dots
\end{bmatrix}$ and $\Delta = \textrm{diag}(\dots, \lambda, \lambda^\*, \dots)$. Assume $\lambda = a + bi$. Now define $\tilde{P}$ by taking $P$ and replacing $v$ with $\mathfrak{Re}(v)$ and $v^\*$ with $\mathfrak{Im}(v)$. Similarly, define $\tilde{\Delta}$ by taking $\Delta$ and replacing the $2 \times 2$ block containing $\lambda$ and $\lambda^\*$ with
\\[\begin{bmatrix}
a & b \\
-b & a
\end{bmatrix}.\\]
It can be shown that $e^{A} = \tilde{P}e^{\tilde{\Delta}}\tilde{P}^{-1}$. We now show that
\\[\exp\left\lbrace {\begin{bmatrix}
a & b \\
-b & a
\end{bmatrix}} \right\rbrace = e^{a}\begin{bmatrix}
\cos{b} & \sin{b} \\
-\sin{b} & \cos{b}
\end{bmatrix}.\\]
